Using cpu device
-----------------------------
| time/              |      |
|    fps             | 44   |
|    iterations      | 1    |
|    time_elapsed    | 22   |
|    total_timesteps | 1024 |
-----------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 49          |
|    iterations           | 2           |
|    time_elapsed         | 41          |
|    total_timesteps      | 2048        |
| train/                  |             |
|    approx_kl            | 0.008105107 |
|    clip_fraction        | 0.0961      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.27       |
|    explained_variance   | 0.00103     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.04e+04    |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.000707   |
|    std                  | 0.37        |
|    value_loss           | 4.2e+04     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 51          |
|    iterations           | 3           |
|    time_elapsed         | 59          |
|    total_timesteps      | 3072        |
| train/                  |             |
|    approx_kl            | 0.015507108 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.27       |
|    explained_variance   | 4.89e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.57e+04    |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.000234   |
|    std                  | 0.368       |
|    value_loss           | 3.21e+04    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 53          |
|    iterations           | 4           |
|    time_elapsed         | 77          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.008815405 |
|    clip_fraction        | 0.0677      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.000177   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.93e+04    |
|    n_updates            | 30          |
|    policy_gradient_loss | 0.00241     |
|    std                  | 0.366       |
|    value_loss           | 4.05e+04    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 51          |
|    iterations           | 5           |
|    time_elapsed         | 99          |
|    total_timesteps      | 5120        |
| train/                  |             |
|    approx_kl            | 0.006731679 |
|    clip_fraction        | 0.0623      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.24       |
|    explained_variance   | -0.000767   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.67e+04    |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00157    |
|    std                  | 0.365       |
|    value_loss           | 1.32e+05    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 52         |
|    iterations           | 6          |
|    time_elapsed         | 117        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.00180423 |
|    clip_fraction        | 0.05       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.23      |
|    explained_variance   | 0.00133    |
|    learning_rate        | 0.0003     |
|    loss                 | 5.83e+04   |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.00227   |
|    std                  | 0.364      |
|    value_loss           | 1.24e+05   |
----------------------------------------
Traceback (most recent call last):
  File "/home/wenjia/CBFRL/gazebo_env/train.py", line 109, in <module>
    main()
  File "/home/wenjia/CBFRL/gazebo_env/train.py", line 74, in main
    model.learn(
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
  File "/home/wenjia/CBFRL/gazebo_env/env_gazebo.py", line 478, in step
    rclpy.spin_once(self, timeout_sec=self.dt)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/__init__.py", line 206, in spin_once
    executor.spin_once(timeout_sec=timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 739, in spin_once
    self._spin_once_impl(timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 728, in _spin_once_impl
    handler, entity, node = self.wait_for_ready_callbacks(timeout_sec=timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 711, in wait_for_ready_callbacks
    return next(self._cb_iter)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 608, in _wait_for_ready_callbacks
    wait_set.wait(timeout_nsec)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/wenjia/CBFRL/gazebo_env/train.py", line 109, in <module>
    main()
  File "/home/wenjia/CBFRL/gazebo_env/train.py", line 74, in main
    model.learn(
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
  File "/home/wenjia/CBFRL/gazebo_env/env_gazebo.py", line 478, in step
    rclpy.spin_once(self, timeout_sec=self.dt)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/__init__.py", line 206, in spin_once
    executor.spin_once(timeout_sec=timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 739, in spin_once
    self._spin_once_impl(timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 728, in _spin_once_impl
    handler, entity, node = self.wait_for_ready_callbacks(timeout_sec=timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 711, in wait_for_ready_callbacks
    return next(self._cb_iter)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 608, in _wait_for_ready_callbacks
    wait_set.wait(timeout_nsec)
KeyboardInterrupt
