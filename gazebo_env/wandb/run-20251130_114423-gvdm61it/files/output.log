Using cpu device
-----------------------------
| time/              |      |
|    fps             | 48   |
|    iterations      | 1    |
|    time_elapsed    | 21   |
|    total_timesteps | 1024 |
-----------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 52          |
|    iterations           | 2           |
|    time_elapsed         | 39          |
|    total_timesteps      | 2048        |
| train/                  |             |
|    approx_kl            | 0.009456587 |
|    clip_fraction        | 0.0992      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | 0.00172     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.86e+04    |
|    n_updates            | 10          |
|    policy_gradient_loss | 0.00183     |
|    std                  | 0.369       |
|    value_loss           | 3.65e+04    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 53          |
|    iterations           | 3           |
|    time_elapsed         | 57          |
|    total_timesteps      | 3072        |
| train/                  |             |
|    approx_kl            | 0.007997788 |
|    clip_fraction        | 0.0825      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.00118    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.28e+04    |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00165    |
|    std                  | 0.367       |
|    value_loss           | 6.73e+04    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 54         |
|    iterations           | 4          |
|    time_elapsed         | 75         |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.00930893 |
|    clip_fraction        | 0.106      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.25      |
|    explained_variance   | -2.62e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 4.22e+04   |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.000656  |
|    std                  | 0.366      |
|    value_loss           | 8.54e+04   |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 50           |
|    iterations           | 5            |
|    time_elapsed         | 101          |
|    total_timesteps      | 5120         |
| train/                  |              |
|    approx_kl            | 0.0057593305 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.23        |
|    explained_variance   | -4.17e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 4.23e+04     |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.000473    |
|    std                  | 0.365        |
|    value_loss           | 8.45e+04     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 51           |
|    iterations           | 6            |
|    time_elapsed         | 119          |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0026758856 |
|    clip_fraction        | 0.0367       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | 4.59e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 3.91e+04     |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00199     |
|    std                  | 0.361        |
|    value_loss           | 7.88e+04     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 52           |
|    iterations           | 7            |
|    time_elapsed         | 137          |
|    total_timesteps      | 7168         |
| train/                  |              |
|    approx_kl            | 0.0062980615 |
|    clip_fraction        | 0.0867       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.2         |
|    explained_variance   | -2.84e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 3.2e+04      |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.000199    |
|    std                  | 0.36         |
|    value_loss           | 6.57e+04     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 52           |
|    iterations           | 8            |
|    time_elapsed         | 155          |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0062045846 |
|    clip_fraction        | 0.0939       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.19        |
|    explained_variance   | -7.15e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 3.37e+04     |
|    n_updates            | 70           |
|    policy_gradient_loss | 0.00191      |
|    std                  | 0.359        |
|    value_loss           | 6.77e+04     |
------------------------------------------
Traceback (most recent call last):
  File "/home/wenjia/CBFRL/gazebo_env/train.py", line 109, in <module>
    main()
  File "/home/wenjia/CBFRL/gazebo_env/train.py", line 74, in main
    model.learn(
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
  File "/home/wenjia/CBFRL/gazebo_env/env_gazebo.py", line 483, in step
    self.pub_twist.publish(self.twist)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/__init__.py", line 206, in spin_once
    executor.spin_once(timeout_sec=timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 739, in spin_once
    self._spin_once_impl(timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 728, in _spin_once_impl
    handler, entity, node = self.wait_for_ready_callbacks(timeout_sec=timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 711, in wait_for_ready_callbacks
    return next(self._cb_iter)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 608, in _wait_for_ready_callbacks
    wait_set.wait(timeout_nsec)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/wenjia/CBFRL/gazebo_env/train.py", line 109, in <module>
    main()
  File "/home/wenjia/CBFRL/gazebo_env/train.py", line 74, in main
    model.learn(
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
  File "/home/wenjia/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
  File "/home/wenjia/CBFRL/gazebo_env/env_gazebo.py", line 483, in step
    self.pub_twist.publish(self.twist)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/__init__.py", line 206, in spin_once
    executor.spin_once(timeout_sec=timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 739, in spin_once
    self._spin_once_impl(timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 728, in _spin_once_impl
    handler, entity, node = self.wait_for_ready_callbacks(timeout_sec=timeout_sec)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 711, in wait_for_ready_callbacks
    return next(self._cb_iter)
  File "/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py", line 608, in _wait_for_ready_callbacks
    wait_set.wait(timeout_nsec)
KeyboardInterrupt
