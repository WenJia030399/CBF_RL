_wandb:
    value:
        cli_version: 0.23.0
        e:
            dj8mbat5fs3artpxtw8hcx1dw3zvj0ow:
                codePath: gazebo_env/train.py
                codePathLocal: train.py
                cpu_count: 8
                cpu_count_logical: 16
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "157396975616"
                        used: "115361341440"
                email: jay030399@gmail.com
                executable: /home/wenjia/miniconda3/envs/rl/bin/python
                git:
                    commit: f97cf4f4c31c51407162f6453f620098e07fa4eb
                    remote: https://github.com/WenJia030399/CBF_RL.git
                gpu: NVIDIA GeForce GTX 1660 Ti with Max-Q Design
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Turing
                      cudaCores: 1536
                      memoryTotal: "6442450944"
                      name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design
                      uuid: GPU-b1958ae1-3061-6273-a56a-c94d3332f362
                host: wenjia-ROG
                memory:
                    total: "16151318528"
                os: Linux-6.8.0-87-generic-x86_64-with-glibc2.35
                program: /home/wenjia/CBFRL/gazebo_env/train.py
                python: CPython 3.10.19
                root: /home/wenjia/CBFRL/gazebo_env
                startedAt: "2025-11-30T03:37:26.022050Z"
                writerId: dj8mbat5fs3artpxtw8hcx1dw3zvj0ow
        m: []
        python_version: 3.10.19
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
            "4": 3.10.19
            "5": 0.23.0
            "12": 0.23.0
            "13": linux-x86_64
batch_size:
    value: 64
gamma:
    value: 0.99
learning_rate:
    value: 0.0003
n_steps:
    value: 1024
policy:
    value: MlpPolicy
